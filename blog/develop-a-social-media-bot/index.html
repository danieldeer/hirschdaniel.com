<!DOCTYPE html>
<html lang="en" dir="ltr">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Developing a Bot to Automate Web Activity on a XenForo-Based Forum | HirschDaniel</title>
<meta name="keywords" content="">
<meta name="description" content="As a software engineer, automation is a natural extension of problem-solving when dealing with repetitive tasks. And in general, if you ever give me any task that involves a hint of repetition, you can expect me to automate it. Automating something complex to save time is both pleasing and rewarding.
Recently, I worked on a project to automate interactions with a XenForo-based forum, saving myself countless hours of manual work. While I won’t disclose the specifics of the forum, the project involved fetching posts, extracting URLs, and automating interactions such as &ldquo;liking&rdquo; posts via HTTP POST requests.">
<meta name="author" content="">
<link rel="canonical" href="https://hirschdaniel.com/blog/develop-a-social-media-bot/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://hirschdaniel.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hirschdaniel.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hirschdaniel.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hirschdaniel.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://hirschdaniel.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://hirschdaniel.com/blog/develop-a-social-media-bot/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
  

<meta property="og:title" content="Developing a Bot to Automate Web Activity on a XenForo-Based Forum" />
<meta property="og:description" content="As a software engineer, automation is a natural extension of problem-solving when dealing with repetitive tasks. And in general, if you ever give me any task that involves a hint of repetition, you can expect me to automate it. Automating something complex to save time is both pleasing and rewarding.
Recently, I worked on a project to automate interactions with a XenForo-based forum, saving myself countless hours of manual work. While I won’t disclose the specifics of the forum, the project involved fetching posts, extracting URLs, and automating interactions such as &ldquo;liking&rdquo; posts via HTTP POST requests." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hirschdaniel.com/blog/develop-a-social-media-bot/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2024-09-22T21:42:22+02:00" />
<meta property="article:modified_time" content="2024-09-22T21:42:22+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Developing a Bot to Automate Web Activity on a XenForo-Based Forum"/>
<meta name="twitter:description" content="As a software engineer, automation is a natural extension of problem-solving when dealing with repetitive tasks. And in general, if you ever give me any task that involves a hint of repetition, you can expect me to automate it. Automating something complex to save time is both pleasing and rewarding.
Recently, I worked on a project to automate interactions with a XenForo-based forum, saving myself countless hours of manual work. While I won’t disclose the specifics of the forum, the project involved fetching posts, extracting URLs, and automating interactions such as &ldquo;liking&rdquo; posts via HTTP POST requests."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://hirschdaniel.com/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Developing a Bot to Automate Web Activity on a XenForo-Based Forum",
      "item": "https://hirschdaniel.com/blog/develop-a-social-media-bot/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Developing a Bot to Automate Web Activity on a XenForo-Based Forum",
  "name": "Developing a Bot to Automate Web Activity on a XenForo-Based Forum",
  "description": "As a software engineer, automation is a natural extension of problem-solving when dealing with repetitive tasks. And in general, if you ever give me any task that involves a hint of repetition, you can expect me to automate it. Automating something complex to save time is both pleasing and rewarding.\nRecently, I worked on a project to automate interactions with a XenForo-based forum, saving myself countless hours of manual work. While I won’t disclose the specifics of the forum, the project involved fetching posts, extracting URLs, and automating interactions such as \u0026ldquo;liking\u0026rdquo; posts via HTTP POST requests.",
  "keywords": [
    
  ],
  "articleBody": "As a software engineer, automation is a natural extension of problem-solving when dealing with repetitive tasks. And in general, if you ever give me any task that involves a hint of repetition, you can expect me to automate it. Automating something complex to save time is both pleasing and rewarding.\nRecently, I worked on a project to automate interactions with a XenForo-based forum, saving myself countless hours of manual work. While I won’t disclose the specifics of the forum, the project involved fetching posts, extracting URLs, and automating interactions such as “liking” posts via HTTP POST requests.\nWhat’s the point? Some of the website’s content was only available to active users. This scratched an itch for me.\nThis post will delve into the technical process of building a bot that fetches forum pages, scrapes post data, and performs automated actions. The core of the project revolved around understanding how web requests work, maintaining session state, and sending authenticated POST requests in bulk to interact with multiple posts.\nProblem: Automating Tedious Web Activity The task was straightforward: I needed to interact with hundreds of posts across multiple pages in a XenForo forum. Manually navigating through the pages and clicking on posts to perform interactions was time-consuming and error-prone.\nThe solution was to develop a bot that could:\nFetch forum pages to get a list of all posts. Scrape the necessary data from each post. Send automated POST requests to perform interactions with each post (such as “liking” them). Approach: HTTP Requests and Sessions To automate this process, I didn’t use a browser automation tool like Selenium. Instead, I opted for a more lightweight solution that involved direct HTTP requests. Here’s a breakdown of the development process:\n1. Understanding the Forum’s Request Structure XenForo forums, like many other web applications, follow a predictable structure for their HTTP requests. Each interaction—whether it’s navigating pages or liking posts—sends a POST request with specific parameters.\nUsing Firefox Developer Tools, I inspected the network traffic generated when I manually liked a post. The key part of the POST request looked like this:\n_xfRequestUri=%2Fthreads%2Fsome-thread.12345%2Fpage-2\u0026_xfWithData=1\u0026_xfToken=xyz123\u0026_xfResponseType=json From this, I identified several important components:\n_xfRequestUri: The URL of the thread or post. _xfToken: A CSRF token used to validate the request. _xfWithData and _xfResponseType: Standard XenForo parameters that control the format of the response. Each “like” was essentially an HTTP POST request with these parameters, and the CSRF token (_xfToken) was refreshed periodically.\nThe Firefox plugin Copy as Python Requests allowed me to translate manual requests with cookies directly to Python code.\n2. Fetching Forum Pages and Extracting URLs The first step was fetching forum pages to identify which posts I needed to interact with. Each page in the thread contained multiple posts, and I needed to scrape the page to extract the URLs of these posts.\nHere’s a rough outline of the Python code I used to fetch the HTML of a page (without cookies etc.):\nimport requests from bs4 import BeautifulSoup # Set up a session to maintain cookies and headers session = requests.Session() # URL of the forum page url = 'https://example.com/threads/some-thread.12345/page-1' # Send GET request to fetch the page response = session.get(url) # Parse the HTML with BeautifulSoup soup = BeautifulSoup(response.text, 'html.parser') # Find all post elements posts = soup.find_all('div', class_='message') # Extract post IDs or URLs post_urls = [post['data-url'] for post in posts] This code:\nOpens an HTTP session to keep cookies (which includes session state). Fetches the HTML of the forum page. Uses BeautifulSoup to parse the page and extract the URLs or post IDs of each post. 3. Scraping Posts on Each Page With the list of URLs or post IDs in hand, I could now automate the interaction process. Each post on a XenForo page had a specific element structure, and I needed to extract the relevant data to perform automated interactions.\n# Function to scrape post details def scrape_posts(page_url): response = session.get(page_url) soup = BeautifulSoup(response.text, 'html.parser') # Find all post blocks on the page posts = soup.find_all('article', class_='message') post_data = [] for post in posts: post_id = post['data-content'] user = post.find('h4', class_='message-author').get_text() post_data.append({ 'post_id': post_id, 'user': user }) return post_data # Scrape a specific page page_posts = scrape_posts('https://example.com/threads/some-thread.12345/page-1') This script allows me to:\nExtract the post ID and user data for each post. Collect all relevant posts on a page for later interaction. 4. Maintaining Session and Cookies When interacting with the forum, maintaining the session was critical. XenForo uses cookies and session tokens to track authenticated users. Fortunately, the Python requests.Session() object manages these automatically after login or initial page access.\n# Login function to authenticate session def login(session, username, password): login_url = 'https://example.com/login' login_data = { 'login': username, 'password': password, '_xfToken': 'your_csrf_token_here' } session.post(login_url, data=login_data) return session # Example of logging in session = login(session, 'my_username', 'my_password') This way, the session remains authenticated as I move across different pages and posts, allowing the bot to send requests without constantly needing to log in.\n5. Sending POST Requests to Interact with Posts Now that I had the list of post IDs and the session was maintained, it was time to automate the “like” action. I emulated the manual process of liking a post by sending POST requests directly.\nHere’s the code that handles sending a POST request for each post:\ndef like_post(post_id): # URL and data payload for liking a post like_url = f'https://example.com/posts/{post_id}/like' post_data = { '_xfToken': 'your_csrf_token_here', '_xfRequestUri': f'/threads/some-thread/post-{post_id}', '_xfWithData': '1', '_xfResponseType': 'json' } # Send POST request to like the post response = session.post(like_url, data=post_data) if response.status_code == 200: print(f'Successfully liked post {post_id}') else: print(f'Failed to like post {post_id}: {response.text}') # Interact with all posts on the current page for post in page_posts: like_post(post['post_id']) In this step:\nI dynamically built the URL for each post, appending the post ID. I constructed the POST request data with the required CSRF token and request URI. Each POST request was sent using the session, ensuring the bot was authenticated. 6. Delays to Mimic Human Interaction To avoid being detected as a bot, I added randomized delays between requests to mimic human activity. Without these delays, rapid requests could trigger rate limits or anti-bot mechanisms on the forum.\nimport time import random # Add a delay between each request for post in page_posts: like_post(post['post_id']) delay = random.uniform(1, 3) # Random delay between 1 and 3 seconds time.sleep(delay) Outcome: Efficient Web Automation This bot saved me hours of manual work by automating the entire process of interacting with posts. The key takeaway is that by understanding how HTTP requests work, maintaining session state, and carefully managing tokens and delays, you can automate complex web tasks without the overhead of browser automation tools like Selenium.\nWithin just a couple of hours, the bot generated enough activity so that the forum considered my profile a trusted and experienced member, and I gained access to all locked content.\nWhether you’re scraping data or automating repetitive tasks, building bots like this can greatly enhance your productivity while giving you more control over how the automation works.\nIf you’re interested in building similar automation for your projects, feel free to reach out, and I’d be happy to help guide you through the process!\n",
  "wordCount" : "1196",
  "inLanguage": "en",
  "datePublished": "2024-09-22T21:42:22+02:00",
  "dateModified": "2024-09-22T21:42:22+02:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hirschdaniel.com/blog/develop-a-social-media-bot/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "HirschDaniel",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hirschdaniel.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hirschdaniel.com/" accesskey="h" title="HirschDaniel (Alt + H)">HirschDaniel</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hirschdaniel.com/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Developing a Bot to Automate Web Activity on a XenForo-Based Forum
    </h1>
    <div class="post-meta"><span title='2024-09-22 21:42:22 +0200 CEST'>September 22, 2024</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#problem-automating-tedious-web-activity" aria-label="Problem: Automating Tedious Web Activity">Problem: Automating Tedious Web Activity</a></li>
                <li>
                    <a href="#approach-http-requests-and-sessions" aria-label="Approach: HTTP Requests and Sessions">Approach: HTTP Requests and Sessions</a><ul>
                        
                <li>
                    <a href="#1-understanding-the-forums-request-structure" aria-label="1. Understanding the Forum&rsquo;s Request Structure">1. Understanding the Forum&rsquo;s Request Structure</a></li>
                <li>
                    <a href="#2-fetching-forum-pages-and-extracting-urls" aria-label="2. Fetching Forum Pages and Extracting URLs">2. Fetching Forum Pages and Extracting URLs</a></li>
                <li>
                    <a href="#3-scraping-posts-on-each-page" aria-label="3. Scraping Posts on Each Page">3. Scraping Posts on Each Page</a></li>
                <li>
                    <a href="#4-maintaining-session-and-cookies" aria-label="4. Maintaining Session and Cookies">4. Maintaining Session and Cookies</a></li>
                <li>
                    <a href="#5-sending-post-requests-to-interact-with-posts" aria-label="5. Sending POST Requests to Interact with Posts">5. Sending POST Requests to Interact with Posts</a></li>
                <li>
                    <a href="#6-delays-to-mimic-human-interaction" aria-label="6. Delays to Mimic Human Interaction">6. Delays to Mimic Human Interaction</a></li></ul>
                </li>
                <li>
                    <a href="#outcome-efficient-web-automation" aria-label="Outcome: Efficient Web Automation">Outcome: Efficient Web Automation</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>As a software engineer, automation is a natural extension of problem-solving when dealing with repetitive tasks. And in general, if you ever give me any task that involves a hint of repetition, you can expect me to automate it. Automating something complex to save time is both pleasing and rewarding.</p>
<p>Recently, I worked on a project to automate interactions with a XenForo-based forum, saving myself countless hours of manual work. While I won’t disclose the specifics of the forum, the project involved fetching posts, extracting URLs, and automating interactions such as &ldquo;liking&rdquo; posts via HTTP POST requests.</p>
<p>What&rsquo;s the point? Some of the website&rsquo;s content was only available to active users. This scratched an itch for me.</p>
<p>This post will delve into the technical process of building a bot that fetches forum pages, scrapes post data, and performs automated actions. The core of the project revolved around understanding how web requests work, maintaining session state, and sending authenticated POST requests in bulk to interact with multiple posts.</p>
<h3 id="problem-automating-tedious-web-activity">Problem: Automating Tedious Web Activity<a hidden class="anchor" aria-hidden="true" href="#problem-automating-tedious-web-activity">#</a></h3>
<p>The task was straightforward: I needed to interact with hundreds of posts across multiple pages in a XenForo forum. Manually navigating through the pages and clicking on posts to perform interactions was time-consuming and error-prone.</p>
<p>The solution was to develop a bot that could:</p>
<ol>
<li><strong>Fetch forum pages</strong> to get a list of all posts.</li>
<li><strong>Scrape the necessary data</strong> from each post.</li>
<li><strong>Send automated POST requests</strong> to perform interactions with each post (such as &ldquo;liking&rdquo; them).</li>
</ol>
<h3 id="approach-http-requests-and-sessions">Approach: HTTP Requests and Sessions<a hidden class="anchor" aria-hidden="true" href="#approach-http-requests-and-sessions">#</a></h3>
<p>To automate this process, I didn’t use a browser automation tool like Selenium. Instead, I opted for a more lightweight solution that involved direct HTTP requests. Here&rsquo;s a breakdown of the development process:</p>
<h4 id="1-understanding-the-forums-request-structure">1. <strong>Understanding the Forum&rsquo;s Request Structure</strong><a hidden class="anchor" aria-hidden="true" href="#1-understanding-the-forums-request-structure">#</a></h4>
<p>XenForo forums, like many other web applications, follow a predictable structure for their HTTP requests. Each interaction—whether it&rsquo;s navigating pages or liking posts—sends a POST request with specific parameters.</p>
<p>Using Firefox Developer Tools, I inspected the network traffic generated when I manually liked a post. The key part of the POST request looked like this:</p>
<pre tabindex="0"><code>_xfRequestUri=%2Fthreads%2Fsome-thread.12345%2Fpage-2&amp;_xfWithData=1&amp;_xfToken=xyz123&amp;_xfResponseType=json
</code></pre><p>From this, I identified several important components:</p>
<ul>
<li><code>_xfRequestUri</code>: The URL of the thread or post.</li>
<li><code>_xfToken</code>: A CSRF token used to validate the request.</li>
<li><code>_xfWithData</code> and <code>_xfResponseType</code>: Standard XenForo parameters that control the format of the response.</li>
</ul>
<p>Each &ldquo;like&rdquo; was essentially an HTTP POST request with these parameters, and the CSRF token (<code>_xfToken</code>) was refreshed periodically.</p>
<p>The Firefox plugin <a href="https://addons.mozilla.org/en-US/firefox/addon/copy-as-python-requests/">Copy as Python Requests</a> allowed me to translate manual requests with cookies directly to Python code.</p>
<h4 id="2-fetching-forum-pages-and-extracting-urls">2. <strong>Fetching Forum Pages and Extracting URLs</strong><a hidden class="anchor" aria-hidden="true" href="#2-fetching-forum-pages-and-extracting-urls">#</a></h4>
<p>The first step was fetching forum pages to identify which posts I needed to interact with. Each page in the thread contained multiple posts, and I needed to scrape the page to extract the URLs of these posts.</p>
<p>Here’s a rough outline of the Python code I used to fetch the HTML of a page (without cookies etc.):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> bs4 <span style="color:#f92672">import</span> BeautifulSoup
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set up a session to maintain cookies and headers</span>
</span></span><span style="display:flex;"><span>session <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>Session()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># URL of the forum page</span>
</span></span><span style="display:flex;"><span>url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;https://example.com/threads/some-thread.12345/page-1&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Send GET request to fetch the page</span>
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>get(url)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Parse the HTML with BeautifulSoup</span>
</span></span><span style="display:flex;"><span>soup <span style="color:#f92672">=</span> BeautifulSoup(response<span style="color:#f92672">.</span>text, <span style="color:#e6db74">&#39;html.parser&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Find all post elements</span>
</span></span><span style="display:flex;"><span>posts <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>find_all(<span style="color:#e6db74">&#39;div&#39;</span>, class_<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;message&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Extract post IDs or URLs</span>
</span></span><span style="display:flex;"><span>post_urls <span style="color:#f92672">=</span> [post[<span style="color:#e6db74">&#39;data-url&#39;</span>] <span style="color:#66d9ef">for</span> post <span style="color:#f92672">in</span> posts]
</span></span></code></pre></div><p>This code:</p>
<ul>
<li>Opens an HTTP session to keep cookies (which includes session state).</li>
<li>Fetches the HTML of the forum page.</li>
<li>Uses <strong>BeautifulSoup</strong> to parse the page and extract the URLs or post IDs of each post.</li>
</ul>
<h4 id="3-scraping-posts-on-each-page">3. <strong>Scraping Posts on Each Page</strong><a hidden class="anchor" aria-hidden="true" href="#3-scraping-posts-on-each-page">#</a></h4>
<p>With the list of URLs or post IDs in hand, I could now automate the interaction process. Each post on a XenForo page had a specific element structure, and I needed to extract the relevant data to perform automated interactions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Function to scrape post details</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">scrape_posts</span>(page_url):
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>get(page_url)
</span></span><span style="display:flex;"><span>    soup <span style="color:#f92672">=</span> BeautifulSoup(response<span style="color:#f92672">.</span>text, <span style="color:#e6db74">&#39;html.parser&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Find all post blocks on the page</span>
</span></span><span style="display:flex;"><span>    posts <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>find_all(<span style="color:#e6db74">&#39;article&#39;</span>, class_<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;message&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    post_data <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> post <span style="color:#f92672">in</span> posts:
</span></span><span style="display:flex;"><span>        post_id <span style="color:#f92672">=</span> post[<span style="color:#e6db74">&#39;data-content&#39;</span>]
</span></span><span style="display:flex;"><span>        user <span style="color:#f92672">=</span> post<span style="color:#f92672">.</span>find(<span style="color:#e6db74">&#39;h4&#39;</span>, class_<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;message-author&#39;</span>)<span style="color:#f92672">.</span>get_text()
</span></span><span style="display:flex;"><span>        post_data<span style="color:#f92672">.</span>append({
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;post_id&#39;</span>: post_id,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;user&#39;</span>: user
</span></span><span style="display:flex;"><span>        })
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> post_data
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Scrape a specific page</span>
</span></span><span style="display:flex;"><span>page_posts <span style="color:#f92672">=</span> scrape_posts(<span style="color:#e6db74">&#39;https://example.com/threads/some-thread.12345/page-1&#39;</span>)
</span></span></code></pre></div><p>This script allows me to:</p>
<ul>
<li>Extract the <strong>post ID</strong> and <strong>user data</strong> for each post.</li>
<li>Collect all relevant posts on a page for later interaction.</li>
</ul>
<h4 id="4-maintaining-session-and-cookies">4. <strong>Maintaining Session and Cookies</strong><a hidden class="anchor" aria-hidden="true" href="#4-maintaining-session-and-cookies">#</a></h4>
<p>When interacting with the forum, maintaining the session was critical. XenForo uses <strong>cookies</strong> and <strong>session tokens</strong> to track authenticated users. Fortunately, the Python <code>requests.Session()</code> object manages these automatically after login or initial page access.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Login function to authenticate session</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">login</span>(session, username, password):
</span></span><span style="display:flex;"><span>    login_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;https://example.com/login&#39;</span>
</span></span><span style="display:flex;"><span>    login_data <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;login&#39;</span>: username,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;password&#39;</span>: password,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;_xfToken&#39;</span>: <span style="color:#e6db74">&#39;your_csrf_token_here&#39;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    session<span style="color:#f92672">.</span>post(login_url, data<span style="color:#f92672">=</span>login_data)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> session
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Example of logging in</span>
</span></span><span style="display:flex;"><span>session <span style="color:#f92672">=</span> login(session, <span style="color:#e6db74">&#39;my_username&#39;</span>, <span style="color:#e6db74">&#39;my_password&#39;</span>)
</span></span></code></pre></div><p>This way, the session remains authenticated as I move across different pages and posts, allowing the bot to send requests without constantly needing to log in.</p>
<h4 id="5-sending-post-requests-to-interact-with-posts">5. <strong>Sending POST Requests to Interact with Posts</strong><a hidden class="anchor" aria-hidden="true" href="#5-sending-post-requests-to-interact-with-posts">#</a></h4>
<p>Now that I had the list of post IDs and the session was maintained, it was time to automate the &ldquo;like&rdquo; action. I emulated the manual process of liking a post by sending POST requests directly.</p>
<p>Here’s the code that handles sending a POST request for each post:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">like_post</span>(post_id):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># URL and data payload for liking a post</span>
</span></span><span style="display:flex;"><span>    like_url <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;https://example.com/posts/</span><span style="color:#e6db74">{</span>post_id<span style="color:#e6db74">}</span><span style="color:#e6db74">/like&#39;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    post_data <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;_xfToken&#39;</span>: <span style="color:#e6db74">&#39;your_csrf_token_here&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;_xfRequestUri&#39;</span>: <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;/threads/some-thread/post-</span><span style="color:#e6db74">{</span>post_id<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;_xfWithData&#39;</span>: <span style="color:#e6db74">&#39;1&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;_xfResponseType&#39;</span>: <span style="color:#e6db74">&#39;json&#39;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Send POST request to like the post</span>
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>post(like_url, data<span style="color:#f92672">=</span>post_data)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> response<span style="color:#f92672">.</span>status_code <span style="color:#f92672">==</span> <span style="color:#ae81ff">200</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Successfully liked post </span><span style="color:#e6db74">{</span>post_id<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Failed to like post </span><span style="color:#e6db74">{</span>post_id<span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>response<span style="color:#f92672">.</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Interact with all posts on the current page</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> post <span style="color:#f92672">in</span> page_posts:
</span></span><span style="display:flex;"><span>    like_post(post[<span style="color:#e6db74">&#39;post_id&#39;</span>])
</span></span></code></pre></div><p>In this step:</p>
<ul>
<li>I dynamically built the URL for each post, appending the post ID.</li>
<li>I constructed the POST request data with the required CSRF token and request URI.</li>
<li>Each POST request was sent using the session, ensuring the bot was authenticated.</li>
</ul>
<h4 id="6-delays-to-mimic-human-interaction">6. <strong>Delays to Mimic Human Interaction</strong><a hidden class="anchor" aria-hidden="true" href="#6-delays-to-mimic-human-interaction">#</a></h4>
<p>To avoid being detected as a bot, I added randomized delays between requests to mimic human activity. Without these delays, rapid requests could trigger rate limits or anti-bot mechanisms on the forum.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add a delay between each request</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> post <span style="color:#f92672">in</span> page_posts:
</span></span><span style="display:flex;"><span>    like_post(post[<span style="color:#e6db74">&#39;post_id&#39;</span>])
</span></span><span style="display:flex;"><span>    delay <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>uniform(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>)  <span style="color:#75715e"># Random delay between 1 and 3 seconds</span>
</span></span><span style="display:flex;"><span>    time<span style="color:#f92672">.</span>sleep(delay)
</span></span></code></pre></div><h3 id="outcome-efficient-web-automation">Outcome: Efficient Web Automation<a hidden class="anchor" aria-hidden="true" href="#outcome-efficient-web-automation">#</a></h3>
<p>This bot saved me hours of manual work by automating the entire process of interacting with posts. The key takeaway is that by understanding how HTTP requests work, maintaining session state, and carefully managing tokens and delays, you can automate complex web tasks without the overhead of browser automation tools like Selenium.</p>
<p>Within just a couple of hours, the bot generated enough activity so that the forum considered my profile a trusted and experienced member, and I gained access to all locked content.</p>
<p>Whether you’re scraping data or automating repetitive tasks, building bots like this can greatly enhance your productivity while giving you more control over how the automation works.</p>
<p>If you’re interested in building similar automation for your projects, feel free to reach out, and I’d be happy to help guide you through the process!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://hirschdaniel.com/blog/practical-vim-commands-for-real-developers/">
    <span class="title">« Prev</span>
    <br>
    <span>Practical Vim Commands for Real Developers</span>
  </a>
  <a class="next" href="https://hirschdaniel.com/blog/advanced-rest-and-http-concepts/">
    <span class="title">Next »</span>
    <br>
    <span>Advanced REST and HTTP: Status Codes, Headers, and Best Practices for Scalable RESTful APIs</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://hirschdaniel.com/">HirschDaniel</a></span> · 
	<span><a href="https://hirschdaniel.com/imprint">Imprint</a></span>

</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
