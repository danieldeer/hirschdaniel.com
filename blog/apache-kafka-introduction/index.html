<!DOCTYPE html>
<html lang="en" dir="ltr">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Apache Kafka Introduction (Architecture made easy) | HirschDaniel</title>
<meta name="keywords" content="">
<meta name="description" content="In today’s world of distributed systems, data moves fast, and applications need to handle huge volumes of data in real time. Whether you&rsquo;re building microservices, integrating external systems, or managing streaming data, ensuring smooth communication between data producers and consumers is crucial. This is where Apache Kafka comes in—a powerful event streaming platform that enables scalable and decoupled data exchange.
A Beginner&rsquo;s Guide to Apache Kafka: Event Streaming Made Easy I’m Daniel Hirsch, a software engineer based in Germany, and in this post, I’ll share insights from my exploration of Apache Kafka, helping you understand its core concepts and how it solves common problems in modern software architectures.">
<meta name="author" content="">
<link rel="canonical" href="https://hirschdaniel.com/blog/apache-kafka-introduction/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://hirschdaniel.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hirschdaniel.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hirschdaniel.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hirschdaniel.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://hirschdaniel.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://hirschdaniel.com/blog/apache-kafka-introduction/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
  

<meta property="og:title" content="Apache Kafka Introduction (Architecture made easy)" />
<meta property="og:description" content="In today’s world of distributed systems, data moves fast, and applications need to handle huge volumes of data in real time. Whether you&rsquo;re building microservices, integrating external systems, or managing streaming data, ensuring smooth communication between data producers and consumers is crucial. This is where Apache Kafka comes in—a powerful event streaming platform that enables scalable and decoupled data exchange.
A Beginner&rsquo;s Guide to Apache Kafka: Event Streaming Made Easy I’m Daniel Hirsch, a software engineer based in Germany, and in this post, I’ll share insights from my exploration of Apache Kafka, helping you understand its core concepts and how it solves common problems in modern software architectures." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hirschdaniel.com/blog/apache-kafka-introduction/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2024-09-13T13:29:49+02:00" />
<meta property="article:modified_time" content="2024-09-13T13:29:49+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Apache Kafka Introduction (Architecture made easy)"/>
<meta name="twitter:description" content="In today’s world of distributed systems, data moves fast, and applications need to handle huge volumes of data in real time. Whether you&rsquo;re building microservices, integrating external systems, or managing streaming data, ensuring smooth communication between data producers and consumers is crucial. This is where Apache Kafka comes in—a powerful event streaming platform that enables scalable and decoupled data exchange.
A Beginner&rsquo;s Guide to Apache Kafka: Event Streaming Made Easy I’m Daniel Hirsch, a software engineer based in Germany, and in this post, I’ll share insights from my exploration of Apache Kafka, helping you understand its core concepts and how it solves common problems in modern software architectures."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://hirschdaniel.com/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Apache Kafka Introduction (Architecture made easy)",
      "item": "https://hirschdaniel.com/blog/apache-kafka-introduction/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Apache Kafka Introduction (Architecture made easy)",
  "name": "Apache Kafka Introduction (Architecture made easy)",
  "description": "In today’s world of distributed systems, data moves fast, and applications need to handle huge volumes of data in real time. Whether you\u0026rsquo;re building microservices, integrating external systems, or managing streaming data, ensuring smooth communication between data producers and consumers is crucial. This is where Apache Kafka comes in—a powerful event streaming platform that enables scalable and decoupled data exchange.\nA Beginner\u0026rsquo;s Guide to Apache Kafka: Event Streaming Made Easy I’m Daniel Hirsch, a software engineer based in Germany, and in this post, I’ll share insights from my exploration of Apache Kafka, helping you understand its core concepts and how it solves common problems in modern software architectures.",
  "keywords": [
    
  ],
  "articleBody": "In today’s world of distributed systems, data moves fast, and applications need to handle huge volumes of data in real time. Whether you’re building microservices, integrating external systems, or managing streaming data, ensuring smooth communication between data producers and consumers is crucial. This is where Apache Kafka comes in—a powerful event streaming platform that enables scalable and decoupled data exchange.\nA Beginner’s Guide to Apache Kafka: Event Streaming Made Easy I’m Daniel Hirsch, a software engineer based in Germany, and in this post, I’ll share insights from my exploration of Apache Kafka, helping you understand its core concepts and how it solves common problems in modern software architectures.\nInstead of reading this blog post, you can also consume (hehe, Kafka pun intended) the content on YouTube: Apache Kafka Introduction (in under 20 minutes)\nWhat Problem Does Kafka Solve? In many applications, there’s a need for different services to communicate by sending and receiving data. For example, a weather app might have a sensor (a data producer) sending temperature data, while the app’s interface (a data consumer) displays that data in real time. As your application grows, so does the number of data producers and consumers, leading to an explosion of connections between them.\nThis tightly coupled communication model is not scalable. You’d have to maintain custom APIs for each connection, making it difficult to change or expand your system. Kafka solves this by providing a centralized platform for managing data exchange between services—decoupling producers and consumers and allowing them to operate independently.\nUnderstanding Event Streaming At its core, Kafka facilitates event streaming, a method for real-time processing of continuous streams of data. Think of Kafka as a cupboard with drawers—each drawer stores a specific type of information. Data producers (services like sensors or user interfaces) add information to these drawers, and data consumers (such as databases or analytics systems) retrieve the information.\nInstead of services directly talking to each other, they simply produce or consume data from Kafka. This means that services don’t need to know about each other’s existence, and they can work independently, which simplifies system architecture and scaling.\nKafka’s Key Components Let’s break down the fundamental components of Kafka:\nBrokers: These are the servers (or a cluster of servers) that store and manage data streams. Brokers handle incoming data from producers and distribute it to consumers. You can have multiple brokers in a Kafka cluster, which ensures fault tolerance and scalability.\nProducers: These are services or systems that generate data. For example, a producer could be a sensor sending weather data or a user posting a message on a social media platform. Producers send data to a specific Kafka topic.\nConsumers: These are the services or applications that read and process data. For instance, a consumer might be a database that stores weather data for future analysis, or an application that displays real-time social media posts.\nTopics: Topics are Kafka’s way of organizing data. Each topic represents a category of data, such as “weather data” or “user messages.” Producers write to topics, and consumers read from topics. This separation ensures data is well-organized, and consumers can subscribe to relevant topics based on their needs.\nPartitions: Kafka splits topics into partitions, which are smaller, more manageable chunks of data. Partitions enable parallel processing, allowing multiple producers and consumers to handle data simultaneously. For example, a topic for user messages might be partitioned by the first letter of the user’s name, ensuring that different partitions can be processed independently.\nEvents: In Apache Kafka, an event represents a record of data, typically composed of a key, value, timestamp, and metadata. Events are central to Kafka’s message streaming architecture, as they are the units of data that flow between producers and consumers. Producers send events to Kafka topics, where they are stored and managed in partitions. A small dive into the structure of events A typical event example in Kafka might look like:\nKey: Identifies the event, such as a user ID. Value: The actual data payload, for instance, “Alice sent $200 to Bob.” Timestamp: The time the event was created or processed. Events are immutable, meaning they can only be appended to topics but not modified once written. This ensures a consistent and reliable stream of data that can be consumed by different services independently and in parallel. By decoupling producers and consumers, Kafka allows for scalable, distributed, and fast processing of events across systems.\nHow Kafka Handles Data When a producer writes data to a Kafka topic, it doesn’t just throw everything into one big pile. Instead, data is appended to a partition in the topic, like adding files to a specific folder. This log-based structure allows Kafka to handle large volumes of data efficiently.\nAs producers write new events to a partition, Kafka keeps track of the index of each event. Similarly, when a consumer reads data, it keeps track of the last index it read, ensuring it doesn’t miss any new data. This sequential access to data means Kafka avoids many of the performance issues found in traditional databases, like memory fragmentation or slow random access.\nProducers write data and track the index Data is always appended to a partition. Never ever does Kafka insert data into the middle of a partition or even modify a log.\nConsumers read data and track their index Data is always read sequentially, meaning that the pointer index pointing at a memory location moves incrementally. Never does it jump from memory location to memory location!\nWhy Kafka Is Fast and Scalable Kafka’s strength lies in its distributed, decentralized architecture. Instead of relying on a single server to store and process data, Kafka allows you to use multiple brokers. Each broker handles a portion of the data, and if one broker goes down, another can take over, ensuring no data is lost.\nBy partitioning topics and distributing them across brokers, Kafka also ensures high throughput. Producers can write to different partitions at the same time, and consumers can read from multiple partitions simultaneously. This parallelism enables Kafka to handle millions of events per second, making it ideal for large-scale, real-time applications.\nConclusion Apache Kafka is a powerful tool for modern applications that need to process and manage vast amounts of real-time data. By decoupling producers and consumers and providing a scalable platform for event streaming, Kafka simplifies the architecture of distributed systems and ensures data flows smoothly, even in the most demanding environments.\nIf you’re building applications that need to handle continuous streams of data efficiently, Kafka is definitely worth considering. I hope this introduction helped clarify how Kafka works and why it’s so widely used in the world of event streaming. Stay tuned for more in-depth posts, and feel free to explore Kafka further on your own!\n",
  "wordCount" : "1126",
  "inLanguage": "en",
  "datePublished": "2024-09-13T13:29:49+02:00",
  "dateModified": "2024-09-13T13:29:49+02:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hirschdaniel.com/blog/apache-kafka-introduction/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "HirschDaniel",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hirschdaniel.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hirschdaniel.com/" accesskey="h" title="HirschDaniel (Alt + H)">HirschDaniel</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://hirschdaniel.com/de/" title="Deutsch"
                            aria-label="Deutsch">De</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hirschdaniel.com/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://hirschdaniel.com/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://hirschdaniel.com/resources/" title="Resources">
                    <span>Resources</span>
                </a>
            </li>
            <li>
                <a href="https://hirschdaniel.com/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Apache Kafka Introduction (Architecture made easy)
    </h1>
    <div class="post-meta"><span title='2024-09-13 13:29:49 +0200 CEST'>September 13, 2024</span>

</div>
  </header> 
  <div class="post-content"><p>In today’s world of distributed systems, data moves fast, and applications need to handle huge volumes of data in real time. Whether you&rsquo;re building microservices, integrating external systems, or managing streaming data, ensuring smooth communication between data producers and consumers is crucial. This is where <strong>Apache Kafka</strong> comes in—a powerful event streaming platform that enables scalable and decoupled data exchange.</p>
<h3 id="a-beginners-guide-to-apache-kafka-event-streaming-made-easy">A Beginner&rsquo;s Guide to Apache Kafka: Event Streaming Made Easy<a hidden class="anchor" aria-hidden="true" href="#a-beginners-guide-to-apache-kafka-event-streaming-made-easy">#</a></h3>
<p>I’m Daniel Hirsch, a software engineer based in Germany, and in this post, I’ll share insights from my exploration of Apache Kafka, helping you understand its core concepts and how it solves common problems in modern software architectures.</p>
<p>Instead of reading this blog post, you can also consume (hehe, Kafka pun intended) the content on YouTube: <a href="https://youtu.be/Ub236INh0XI?si=nmJO-BtkJs6s5H7M">Apache Kafka Introduction (in under 20 minutes)</a></p>
<p><a href="https://youtu.be/Ub236INh0XI?si=2Y5qmR1R5EDwrU0v"><img loading="lazy" src="/image/apache-kafka-video-thumbnail.png" alt="youtube video about apache kafka thumbnail"  />
</a></p>
<h3 id="what-problem-does-kafka-solve">What Problem Does Kafka Solve?<a hidden class="anchor" aria-hidden="true" href="#what-problem-does-kafka-solve">#</a></h3>
<p>In many applications, there’s a need for different services to communicate by sending and receiving data. For example, a weather app might have a sensor (a data producer) sending temperature data, while the app’s interface (a data consumer) displays that data in real time. As your application grows, so does the number of data producers and consumers, leading to an explosion of connections between them.</p>
<p>This tightly coupled communication model is not scalable. You’d have to maintain custom APIs for each connection, making it difficult to change or expand your system. <strong>Kafka solves this by providing a centralized platform for managing data exchange between services</strong>—decoupling producers and consumers and allowing them to operate independently.</p>
<h3 id="understanding-event-streaming">Understanding Event Streaming<a hidden class="anchor" aria-hidden="true" href="#understanding-event-streaming">#</a></h3>
<p>At its core, Kafka facilitates <strong>event streaming</strong>, a method for real-time processing of continuous streams of data. Think of Kafka as a <strong>cupboard with drawers</strong>—each drawer stores a specific type of information. Data producers (services like sensors or user interfaces) add information to these drawers, and data consumers (such as databases or analytics systems) retrieve the information.</p>
<p><img loading="lazy" src="/image/kafka-presentation/Slide3.PNG" alt="kafka analogy for event streaming"  />
</p>
<p>Instead of services directly talking to each other, they simply produce or consume data from Kafka. This means that services don’t need to know about each other’s existence, and they can work independently, which simplifies system architecture and scaling.</p>
<h3 id="kafkas-key-components">Kafka’s Key Components<a hidden class="anchor" aria-hidden="true" href="#kafkas-key-components">#</a></h3>
<p>Let’s break down the fundamental components of Kafka:</p>
<ol>
<li>
<p><strong>Brokers</strong>: These are the servers (or a cluster of servers) that store and manage data streams. Brokers handle incoming data from producers and distribute it to consumers. You can have multiple brokers in a Kafka cluster, which ensures fault tolerance and scalability.</p>
</li>
<li>
<p><strong>Producers</strong>: These are services or systems that generate data. For example, a producer could be a sensor sending weather data or a user posting a message on a social media platform. Producers send data to a specific Kafka <strong>topic</strong>.</p>
</li>
<li>
<p><strong>Consumers</strong>: These are the services or applications that read and process data. For instance, a consumer might be a database that stores weather data for future analysis, or an application that displays real-time social media posts.</p>
</li>
</ol>
<p><img loading="lazy" src="/image/kafka-presentation/Slide4.PNG" alt="Brokers, Consumers, and Producers"  />
</p>
<ol start="4">
<li>
<p><strong>Topics</strong>: Topics are Kafka’s way of organizing data. Each topic represents a category of data, such as “weather data” or “user messages.” <strong>Producers write to topics</strong>, and <strong>consumers read from topics</strong>. This separation ensures data is well-organized, and consumers can subscribe to relevant topics based on their needs.</p>
</li>
<li>
<p><strong>Partitions</strong>: Kafka splits topics into <strong>partitions</strong>, which are smaller, more manageable chunks of data. Partitions enable <strong>parallel processing</strong>, allowing multiple producers and consumers to handle data simultaneously. For example, a topic for user messages might be partitioned by the first letter of the user’s name, ensuring that different partitions can be processed independently.</p>
</li>
</ol>
<p><img loading="lazy" src="/image/kafka-presentation/Slide6.PNG" alt="Topics and Partitions"  />
</p>
<ol start="6">
<li><strong>Events</strong>: In Apache Kafka, an <strong>event</strong> represents a record of data, typically composed of a key, value, timestamp, and metadata. Events are central to Kafka’s message streaming architecture, as they are the units of data that flow between producers and consumers. Producers send events to Kafka <strong>topics</strong>, where they are stored and managed in <strong>partitions</strong>.</li>
</ol>
<h4 id="a-small-dive-into-the-structure-of-events">A small dive into the structure of events<a hidden class="anchor" aria-hidden="true" href="#a-small-dive-into-the-structure-of-events">#</a></h4>
<p>A typical event example in Kafka might look like:</p>
<ul>
<li><strong>Key</strong>: Identifies the event, such as a user ID.</li>
<li><strong>Value</strong>: The actual data payload, for instance, &ldquo;Alice sent $200 to Bob.&rdquo;</li>
<li><strong>Timestamp</strong>: The time the event was created or processed.</li>
</ul>
<p><img loading="lazy" src="/image/kafka-presentation/Slide7.PNG" alt="Events"  />
</p>
<p>Events are immutable, meaning they can only be appended to topics but not modified once written. This ensures a consistent and reliable stream of data that can be consumed by different services independently and in parallel. By decoupling producers and consumers, Kafka allows for scalable, distributed, and fast processing of events across systems.</p>
<h3 id="how-kafka-handles-data">How Kafka Handles Data<a hidden class="anchor" aria-hidden="true" href="#how-kafka-handles-data">#</a></h3>
<p>When a producer writes data to a Kafka topic, it doesn’t just throw everything into one big pile. Instead, data is appended to a partition in the topic, like adding files to a specific folder. This <strong>log-based structure</strong> allows Kafka to handle large volumes of data efficiently.</p>
<p>As producers write new events to a partition, Kafka keeps track of the <strong>index</strong> of each event. Similarly, when a consumer reads data, it keeps track of the last index it read, ensuring it doesn’t miss any new data. This <strong>sequential access</strong> to data means Kafka avoids many of the performance issues found in traditional databases, like memory fragmentation or slow random access.</p>
<h4 id="producers-write-data-and-track-the-index">Producers write data and track the index<a hidden class="anchor" aria-hidden="true" href="#producers-write-data-and-track-the-index">#</a></h4>
<p><img loading="lazy" src="/image/kafka-presentation/Slide8.PNG" alt="Kafka logs Events in Topic Partitions"  />
</p>
<p>Data is always appended to a partition. Never ever does Kafka insert data into the middle of a partition or even modify a log.</p>
<h4 id="consumers-read-data-and-track-their-index">Consumers read data and track their index<a hidden class="anchor" aria-hidden="true" href="#consumers-read-data-and-track-their-index">#</a></h4>
<p><img loading="lazy" src="/image/kafka-presentation/Slide9.PNG" alt="Consumers read logged Events from Topics"  />

Data is always read sequentially, meaning that the pointer index pointing at a memory location moves incrementally. Never does it jump from memory location to memory location!</p>
<h3 id="why-kafka-is-fast-and-scalable">Why Kafka Is Fast and Scalable<a hidden class="anchor" aria-hidden="true" href="#why-kafka-is-fast-and-scalable">#</a></h3>
<p>Kafka’s strength lies in its <strong>distributed, decentralized architecture</strong>. Instead of relying on a single server to store and process data, Kafka allows you to use multiple brokers. Each broker handles a portion of the data, and if one broker goes down, another can take over, ensuring no data is lost.</p>
<p>By partitioning topics and distributing them across brokers, Kafka also ensures <strong>high throughput</strong>. Producers can write to different partitions at the same time, and consumers can read from multiple partitions simultaneously. This parallelism enables Kafka to handle millions of events per second, making it ideal for large-scale, real-time applications.</p>
<h3 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h3>
<p>Apache Kafka is a powerful tool for modern applications that need to process and manage vast amounts of real-time data. By decoupling producers and consumers and providing a scalable platform for event streaming, Kafka simplifies the architecture of distributed systems and ensures data flows smoothly, even in the most demanding environments.</p>
<p>If you&rsquo;re building applications that need to handle continuous streams of data efficiently, Kafka is definitely worth considering. I hope this introduction helped clarify how Kafka works and why it&rsquo;s so widely used in the world of event streaming. Stay tuned for more in-depth posts, and feel free to explore Kafka further on your own!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="https://hirschdaniel.com/blog/decompile-java-crackme-and-develop-keygen/">
    <span class="title">Next »</span>
    <br>
    <span>How to: Decompile Java Crackme and Develop a Keygen</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://hirschdaniel.com/">HirschDaniel</a></span> · 
	<span><a href="https://hirschdaniel.com/imprint">Imprint</a></span>

</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
